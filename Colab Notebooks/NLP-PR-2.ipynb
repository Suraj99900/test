{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNy0vHuC+kYFteZC14rezpV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**NLP-PR-2**"],"metadata":{"id":"HnafDVvx80sX"}},{"cell_type":"markdown","source":["2] To perform various preprocessing tasks in NLP:\n","Perform various basic pre-processing tasks like tokenization, stemming, lemmatization, stop\n","word removal etc. using inbuilt functions and using regular expressions."],"metadata":{"id":"Ws_erRtf8yut"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"3LlWeDBG8yGL","executionInfo":{"status":"ok","timestamp":1744695521716,"user_tz":-330,"elapsed":556,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}}},"outputs":[],"source":["import re\n","import nltk\n","import spacy\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n"]},{"cell_type":"code","source":["# Download required resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","# Download the punkt_tab resource\n","nltk.download('punkt_tab') # Download the necessary data for tokenization\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1IpSJtc9BNm","executionInfo":{"status":"ok","timestamp":1744695570398,"user_tz":-330,"elapsed":11,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"12f3a884-1bed-4021-b8a3-7c8c493ba6c7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Sample text\n","text = \"Natural Language Processing (NLP) is evolving rapidly, enabling machines to understand human language.\"\n"],"metadata":{"id":"KcIzT0Pv9DZo","executionInfo":{"status":"ok","timestamp":1744695493182,"user_tz":-330,"elapsed":9,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# ============================\n","# 1. Using Inbuilt Libraries\n","# ============================\n","\n","print(\"\\nðŸ”¹ Preprocessing Using NLTK & spaCy\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pq85H-V9GFy","executionInfo":{"status":"ok","timestamp":1744695493182,"user_tz":-330,"elapsed":8,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"5c4fac01-5a6d-4eb7-fe41-ddc49f3af790"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Preprocessing Using NLTK & spaCy\n"]}]},{"cell_type":"code","source":["# Tokenization\n","tokens = word_tokenize(text)\n","print(f\"\\nTokens (NLTK): {tokens}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmG8p61V9Izd","executionInfo":{"status":"ok","timestamp":1744695600111,"user_tz":-330,"elapsed":793,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"62be271d-174b-459e-ee9e-9a96e5b5ce0d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Tokens (NLTK): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'evolving', 'rapidly', ',', 'enabling', 'machines', 'to', 'understand', 'human', 'language', '.']\n"]}]},{"cell_type":"code","source":["# Stopword Removal\n","stop_words = set(stopwords.words('english'))\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n","print(f\"\\nFiltered Tokens (No Stopwords): {filtered_tokens}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0ifFcqT9nPK","executionInfo":{"status":"ok","timestamp":1744695622673,"user_tz":-330,"elapsed":8,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"757617d0-b5ec-4d32-bd7e-c4152f5bf48d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Filtered Tokens (No Stopwords): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'evolving', 'rapidly', ',', 'enabling', 'machines', 'understand', 'human', 'language', '.']\n"]}]},{"cell_type":"code","source":["# Stemming\n","stemmer = PorterStemmer()\n","stemmed = [stemmer.stem(word) for word in filtered_tokens]\n","print(f\"\\nStemmed Tokens: {stemmed}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc246B1S9ji0","executionInfo":{"status":"ok","timestamp":1744695627970,"user_tz":-330,"elapsed":6,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"e4127dd6-073f-4a29-f894-07d54f841452"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Stemmed Tokens: ['natur', 'languag', 'process', '(', 'nlp', ')', 'evolv', 'rapidli', ',', 'enabl', 'machin', 'understand', 'human', 'languag', '.']\n"]}]},{"cell_type":"code","source":["# Lemmatization\n","lemmatizer = WordNetLemmatizer()\n","lemmatized = [lemmatizer.lemmatize(word.lower()) for word in filtered_tokens]\n","print(f\"\\nLemmatized Tokens: {lemmatized}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aW_quci9rPN","executionInfo":{"status":"ok","timestamp":1744695642485,"user_tz":-330,"elapsed":3388,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"c116ed36-051a-4c15-c18d-a4dae19906a2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Lemmatized Tokens: ['natural', 'language', 'processing', '(', 'nlp', ')', 'evolving', 'rapidly', ',', 'enabling', 'machine', 'understand', 'human', 'language', '.']\n"]}]},{"cell_type":"code","source":["# ============================\n","# 2. Using Regular Expressions\n","# ============================\n","\n","print(\"\\nðŸ”¹ Preprocessing Using Regular Expressions\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riyXDKg19tTI","executionInfo":{"status":"ok","timestamp":1744695647423,"user_tz":-330,"elapsed":8,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"ba2c39b2-7314-4e08-e961-06f07589cef8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Preprocessing Using Regular Expressions\n"]}]},{"cell_type":"code","source":["# Lowercase and remove punctuation\n","text_clean = re.sub(r'[^\\w\\s]', '', text.lower())\n","print(f\"\\nCleaned Text: {text_clean}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCrOZyVs9vVu","executionInfo":{"status":"ok","timestamp":1744695656195,"user_tz":-330,"elapsed":15,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"e7941da5-f7c1-4cd6-dd36-3657e562161a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cleaned Text: natural language processing nlp is evolving rapidly enabling machines to understand human language\n"]}]},{"cell_type":"code","source":["# Tokenization (RegEx-based)\n","regex_tokens = re.findall(r'\\b\\w+\\b', text_clean)\n","print(f\"\\nTokens (Regex): {regex_tokens}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30bdSIz_9w9B","executionInfo":{"status":"ok","timestamp":1744695662449,"user_tz":-330,"elapsed":12,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"a0819678-b2a9-4566-b182-f98341ab247f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Tokens (Regex): ['natural', 'language', 'processing', 'nlp', 'is', 'evolving', 'rapidly', 'enabling', 'machines', 'to', 'understand', 'human', 'language']\n"]}]},{"cell_type":"code","source":["# Manual Stopword Removal\n","manual_stopwords = {'is', 'to', 'the', 'and', 'a', 'an', 'of', 'in', 'on'}\n","manual_filtered = [word for word in regex_tokens if word not in manual_stopwords]\n","print(f\"\\nFiltered Tokens (Manual Stopwords): {manual_filtered}\")\n"],"metadata":{"id":"ovAu63Zs9y0D","executionInfo":{"status":"ok","timestamp":1744695670122,"user_tz":-330,"elapsed":16,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"372f8921-3a7a-4987-fef0-7402fcec85a4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Filtered Tokens (Manual Stopwords): ['natural', 'language', 'processing', 'nlp', 'evolving', 'rapidly', 'enabling', 'machines', 'understand', 'human', 'language']\n"]}]},{"cell_type":"code","source":["\n","# Manual Stemming (basic example)\n","manual_stemmed = [re.sub(r'(ing|ed|ly|s)$', '', word) for word in manual_filtered]\n","print(f\"\\nStemmed Tokens (Regex-based): {manual_stemmed}\")"],"metadata":{"id":"L9rMJYRn90rV","executionInfo":{"status":"ok","timestamp":1744695677454,"user_tz":-330,"elapsed":14,"user":{"displayName":"Suraj Jaiswal","userId":"15975852039663442884"}},"outputId":"de692df4-1c9c-4087-daf9-1f681f8c68f8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Stemmed Tokens (Regex-based): ['natural', 'language', 'process', 'nlp', 'evolv', 'rapid', 'enabl', 'machine', 'understand', 'human', 'language']\n"]}]}]}